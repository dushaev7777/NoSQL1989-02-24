# Задание №1 #
1. Cохранить большой жсон (~20МБ) в виде разных структур - строка, hset, zset, list;
2. Протестировать скорость сохранения и чтения;

# Решение #

1) СУБД Redis будет установлена на ВМ созданной в Hyper-V с параметрами:
   * Процессор — 2,1 ГГц (1 ядро)
   * Память - 4 ГБ
   * Хранилище - ssd m2 10 ГБ
   * Операционная система — CentOS 7.9
   * Имена хостов — Redis_01.localdomain
   * IP-адреса — 192.168.0.91

Произведем установку свежей версии Redis из исходников, скачиваем репозиторий:
```
[root@Redis_01 ~]# wget https://github.com/redis/redis/archive/7.2.3.tar.gz
```
Устанавливаем пакеты Python и компилятор Gcc:
```
[root@Redis_01 ~]# sudo yum install python3 python3-devel python3-pip
[root@Redis_01 ~]# sudo yum install python3 gcc
```
Создаем каталог и распаковываем архив:
```
[root@Redis_01 ~]# mkdir -p /usr/local/redis7
[root@Redis_01 ~]# tar -zxvf 7.2.3.tar.gz -C /usr/local/redis7/
```
Переходим в каталог с распакованным Redis запускаем компиляцию исходных файлов:
```
[root@Redis_01 ~]# cd /usr/local/redis7/redis-7.2.3
[root@Redis_01 redis-7.2.3]# make
```
Устанавливаем скомпилированные пакеты
```
[root@Redis_01 redis-7.2.3]# make install
cd src && make install
make[1]: Вход в каталог `/usr/local/redis7/redis-7.2.3/src'
    CC Makefile.dep
make[1]: Выход из каталога `/usr/local/redis7/redis-7.2.3/src'
make[1]: Вход в каталог `/usr/local/redis7/redis-7.2.3/src'

Hint: It's a good idea to run 'make test' ;)

    INSTALL redis-server
    INSTALL redis-benchmark
    INSTALL redis-cli
make[1]: Выход из каталога `/usr/local/redis7/redis-7.2.3/src'
```
Создаем сервис и прописываем настройки:
```
[root@Redis_01 redis-7.2.3]# vi /etc/systemd/system/redis.service
[Unit]
Description=redis-server
After=network.target

[Service]
Type=forking
ExecStart=/usr/local/bin/redis-server /usr/local/redis7/redis-7.2.1/redis.conf
PrivateTmp=true

[Install]
WantedBy=multi-user.target

[root@Redis_01 redis-7.2.3]# systemctl daemon-reload
```
Настроим конфигурацию СУБД Redis для этого добавим строки в redis.conf:
```
[root@Redis_01 ~] vi /usr/local/redis7/redis-7.2.3/redis.conf

port 6379 -----------------------------------------Порт для подключения
daemonize yes -------------------------------------Для работы сервера в фоновом режиме
protected-mode no ---------------------------------Отключаем защищенный режим
logfile “/usr/local/redis7/logs/redis.log” --------Каталог для логов
```
Создадим каталог для логов и запустим службу Redis:
```
[root@Redis_01 ~] mkdir -p /usr/local/redis7/logs
[root@Redis_01 ~] systemctl start redis
[root@Redis_01 ~]# systemctl status redis
● redis.service - redis-server
   Loaded: loaded (/etc/systemd/system/redis.service; disabled; vendor preset: disabled)
   Active: active (running) since Вс 2023-12-24 19:00:41 MSK; 2s ago
  Process: 1667 ExecStart=/usr/local/bin/redis-server /usr/local/redis7/redis-7.2.3/redis.conf (code=exited, status=0/SUCCESS)
 Main PID: 1669 (redis-server)
   CGroup: /system.slice/redis.service
           └─1669 /usr/local/bin/redis-server 127.0.0.1:6379

дек 24 19:00:41 Redis_01.localdomain systemd[1]: Stopped redis-server.
дек 24 19:00:41 Redis_01.localdomain systemd[1]: Starting redis-server...
дек 24 19:00:41 Redis_01.localdomain systemd[1]: Started redis-server.
[root@Redis_01 ~]# redis-cli ping
PONG
```
2) Нагенерим данных в файл который будем заливать в БД построчно и списком:
```
[root@Redis_01 ~]# for x in {1..200000}; do echo "SET user:$x $x" >> set.txt; done;

[root@Redis_01 ~]# time cat set.txt | redis-cli
OK
OK
OK

real    0m11.310s
user    0m1.119s
sys     0m2.915s
```
Залили данные поштучно, то есть 200000 записей, это же количество транзакций по сети. Считаем внесенные данные:
```
127.0.0.1:6379> keys *
199980) "user:171305"
199981) "user:57129"
199982) "user:116149"
199983) "user:76685"
199984) "user:60194"
199985) "user:168225"
199986) "user:17221"
199987) "user:38504"
199988) "user:109801"
199989) "user:51276"
199990) "user:168809"
199991) "user:40193"
199992) "user:157203"
199993) "user:64460"
199994) "user:38916"
199995) "user:166758"
199996) "user:122034"
199997) "user:149178"
199998) "user:133914"
199999) "user:151911"
200000) "user:36041"
(2.74s)
```
Очистим данные и еще раз зальем данные только теперь уже списком с помощью pipeline(конвеерная обработка):
```
127.0.0.1:6379> flushdb
OK
[root@Redis_01 ~]# time cat set.txt | redis-cli --pipe
All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 200000

real    0m0.356s
user    0m0.023s
sys     0m0.047s

127.0.0.1:6379> keys *
199980) "user:171305"
199981) "user:57129"
199982) "user:116149"
199983) "user:76685"
199984) "user:60194"
199985) "user:168225"
199986) "user:17221"
199987) "user:38504"
199988) "user:109801"
199989) "user:51276"
199990) "user:168809"
199991) "user:40193"
199992) "user:157203"
199993) "user:64460"
199994) "user:38916"
199995) "user:166758"
199996) "user:122034"
199997) "user:149178"
199998) "user:133914"
199999) "user:151911"
200000) "user:36041"
(2.88s)
```
Как видно из результатов с помощью конвеерной обработки увеличилась скорость записи в 10ки раз. Скорость чтения особо не изменилась.
Нагенерим данных для хеш таблиц и зальем в БД:
```
[root@Redis_01 ~]# for x in {1..200000}; do echo "HSET  title:$x id $x" >> hset.txt; done;
[root@Redis_01 ~]# time cat hset.txt | redis-cli
(integer) 1
(integer) 1
(integer) 1
(integer) 1

real    0m11.891s
user    0m1.322s
sys     0m2.856s

127.0.0.1:6379> keys title*
199980) "title:90920"
199981) "title:4731"
199982) "title:68204"
199983) "title:169750"
199984) "title:120289"
199985) "title:152977"
199986) "title:52049"
199987) "title:119659"
199988) "title:109790"
199989) "title:160370"
199990) "title:91900"
199991) "title:55831"
199992) "title:43684"
199993) "title:171198"
199994) "title:138000"
199995) "title:131194"
199996) "title:173092"
199997) "title:2693"
199998) "title:81391"
199999) "title:19626"
200000) "title:174512"
(2.82s)

127.0.0.1:6379> flushdb
OK

[root@Redis_01 ~]# time cat hset.txt | redis-cli --pipe
All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 200000

real    0m0.466s
user    0m0.018s
sys     0m0.047s

127.0.0.1:6379> keys title*
199980) "title:55831"
199981) "title:43684"
199982) "title:171198"
199983) "title:144904"
199984) "title:138000"
199985) "title:96966"
199986) "title:73503"
199987) "title:131194"
199988) "title:173092"
199989) "title:80024"
199990) "title:195894"
199991) "title:2693"
199992) "title:81391"
199993) "title:19626"
199994) "title:51111"
199995) "title:44630"
199996) "title:94494"
199997) "title:100660"
199998) "title:126022"
199999) "title:174512"
200000) "title:104566"
(3.19s)
```
Также скорость записи в разы выше при конвеерной обработке.
Нагенерим данных ZSET для загрузки в БД используется команда ZADD:
```
[root@Redis_01 ~]# for x in {1..200000}; do echo "ZADD  range:$x $x $x" >> zset.txt; done;
[root@Redis_01 ~]# time cat zset.txt | redis-cli
(integer) 0
(integer) 0
(integer) 0
(integer) 0

real    0m11.514s
user    0m1.330s
sys     0m2.812s

[root@Redis_01 ~]# time cat zset.txt | redis-cli --pipe
All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 200000

real    0m0.373s
user    0m0.017s
sys     0m0.049s
```
Нагенерим данных List для загрузки в БД используется команда LPUSH (добавляет новый элемент в начало списка) и RPUSH (добавляет в конец списка):
```
[root@Redis_01 ~]# for x in {1..100000}; do echo "RPUSH id:$x $x" >> rlist.txt; done;
[root@Redis_01 ~]# for x in {100001..200000}; do echo "LPUSH id:$x $x" >> llist.txt; done;
[root@Redis_01 ~]# time cat llist.txt | redis-cli --pipe
All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 100000

real    0m0.207s
user    0m0.009s
sys     0m0.029s
[root@Redis_01 ~]# time cat rlist.txt | redis-cli --pipe
All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 100000

real    0m0.222s
user    0m0.008s
sys     0m0.031s

127.0.0.1:6379> keys id*
199980) "id:30684"
199981) "id:147860"
199982) "id:129705"
199983) "id:126204"
199984) "id:79481"
199985) "id:131825"
199986) "id:33145"
199987) "id:154797"
199988) "id:141214"
199989) "id:179293"
199990) "id:5793"
199991) "id:132851"
199992) "id:149017"
199993) "id:143238"
199994) "id:35670"
199995) "id:23104"
199996) "id:53641"
199997) "id:87274"
199998) "id:105884"
199999) "id:146378"
200000) "id:107766"
(2.79s)
```

### Выводы:
* Научился устанавливать Redis из исходников
* Создал разного вида ключ-значения и по разному залил их в БД
* Загрузка данных списком с помощью pipeline в разы быстрее и снижает нагрузку на сеть
* Чтение всех 200000 ключей разных ввидов в целом занимает одинаковое время на одной ноде.